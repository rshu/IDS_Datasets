\section{Existing IDS Dataset}


\subsection{ADFA Linux Dataset (ADFA-LD12)}

\textbf{Cited papers:} ~\cite{creech2014semantic} ~\cite{creech2013generation}~\cite{xie2014evaluating} \newline
\textbf{Description:} This dataset is generated based on Ubuntu Linux version 11.04, which runs a Linux web server and services with known vulnerabilities. It provides some services such as file sharing, database services, remote access and web server. This dataset recorded  the traces under attacks as described in the following table. \newline

\begin{table}[h]
\begin{tabular}{|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Payload/Effect}} & \multicolumn{1}{c|}{\textbf{Attack Vector}} \\ \hline
Password bruteforce & FTP by Hydra \\ \hline
Password bruteforce & SSH by Hydra \\ \hline
Add new superuser & Client side poisoned executable \\ \hline
Java Base Meterpreter & Tiki Wiki vulnerability exploit \\ \hline
Linux Meterpreter payload & Client side poisoned executable \\ \hline
C100 Webshell & \begin{tabular}[c]{@{}l@{}}PHP Remote File Inclusion \\ vulnerability\end{tabular} \\ \hline
\end{tabular}
\caption{Attack Structure}
\end{table}

\textbf{Research Goals:} ADFA-LD12 is designed for anomaly based systems, not for signature recognition IDS. Compared with old datasets such as KDD 98 and KDD 99, this dataset is much more representative of current attacks, and forms a realistic  and relevant metric for IDS performance metrics. Authors in the papers proposed a  new host-based anomaly detection method using discontiguous system call pattern on the ADFA dataset in an attempt to increase detection rate while reducing false alarm rates.\newline
\textbf{Data Structure:} This dataset contains three different data groups, and each group contains raw system call traces. Each training or validation data trace  was collected during normal operation of the host. Traces are generated using the auditd Unix program and then filtered by size. The training data has a size  with range 300 Bytes and 6KB, while the validation data keeps a size between 300 Bytes and 10KB. However, we could not get more details to infer the attributes from the description of the paper.\newline

\begin{table}[h]
\begin{tabular}{|l|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Data Type}} & \textbf{Trace Count} \\ \hline
Normal Training Data & 833 Traces \\ \hline
Normal Validation Data & 4373 Traces \\ \hline
Attack Data & 100 Attacks per Vector \\ \hline
\end{tabular}
\caption{Dataset Structure}
\end{table}

\textbf{Evaluation Measurements:} The validity of the data set was examined by evaluating the performance of several IDS algorithms, i.e., hidden Markov models, the STIDE approach, K-Means clustering, and the K-Nearest Neighbour algorithm, and proposed semantic based methods. The result shows that the proposed method achieves a higher detection rate with a lower false alarm rate when compared with other algorithms.\newline


\subsection{CDX 2009}
\textbf{Cited papers:} ~\cite{homoliak2013asnm} ~\cite{sangster2009toward}~\cite{chen2014human}\newline
\textbf{Description:} This dataset contains data captured by NSA, data captured outside of the West Point network border and snort intrusion prevension log. The CDX dataset increases the scale of the network by demonstrating attack attempts from a 30 person red team using IP addresses from a pool of over sixty-five thousand host addresses against workstations, network devices, internal web servers, domain name servers, email servers, and chat servers from the 9 different collegiate team networks.\newline
\textbf{Research Goals:} To create a network based detection system for online defense against zero-day buffer overflow attacks in the production environment~\cite{homoliak2013asnm}. \newline
\textbf{Data Structure:} This dataset is a labeled dataset, and TCP dump traces includes all simulated communications and snort logs include information about the occurances of intrusions. \newline
\textbf{Evaluation Measurements:} \newline
























\subsection{DARPA Intrusion Detection Data Sets, 98, 99, 2000}
\textbf{Cited papers:} \newline
\textbf{Description:} The datasets contained labeled data generated by simulating network traffic for a medium size U.S. Air Force base. The DARPA data sets represent the traffic of a relatively small network of 33 live and simulated hosts interacting with a total of 12 external hosts.The dataset was constructed for network security analysis and exposed the issues associated with the artificial injection of attacks and benign traffic. This dataset includes email, browsing, FTP, Telnet, IRC, and SNMP activities. It contains attacks such as DoS, Guess password, Buffer overflow, remote FTP, Syn flood, Nmap, and Rootkit.\newline
\textbf{Research Goals:} The labeled DARPA datasets of 1998 and 1999 were the security community benchmark for testing intrusion.
detection systems. \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline






\subsection{KDD CUP 98\&99 Dataset}
\textbf{Cited papers:}\newline
\textbf{Description:}This dataset is an updated version of the DARPA98,
by processing the tcpdump portion. It contains different attacks such as Neptune-DoS, pod-DoS, Smurf-DoS, and buffer-overflow. The KDD experiments are performed on a Solaris-based system to collect a wide range of data. System calls are generated by processing the BSM audit data. 
\textbf{Research Goals:} This dataset is usually used to evaluate new intrusion detection methods based on analyzing network traffic. \newline
\textbf{Data Structure:} The training dataset consists of approximately 4.9 million
single connection vectors, each labeled as either normal or attack, containing 41 features per connection record. \newline
\textbf{Evaluation Measurements:} \newline










\subsection{DEFCON dataset}
\textbf{Cited papers:} ~\cite{nehinbe2009simple} \newline
\textbf{Description:} The
DEFCON-8 dataset created in 2000 contains port scanning and buffer overflow attacks, whereas DEFCON-10 dataset, which was created in 2002,
contains port scan and sweeps, bad packets, administrative privilege, and FTP by Telnet protocol attacks\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline





\subsection{CAIDA}
\textbf{Cited papers:}~\cite{shiravi2012toward} \newline
\textbf{Description:} This organization has three different datasets, the CAIDA OC48, which includes different types of data observed on an OC48 link in San Jose, the CAIDA DDOS, which includes one-hour DDoS attack traffic split of 5-minute pcap files, and the CAIDA Internet traces 2016, which is passive traffic traces from CAIDAâ€™s Equinix-Chicago monitor on
the High-speed Internet backbone\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline




\subsection{Kyoto}
\textbf{Cited papers:} ~\cite{song2011statistical}~\cite{sato2012unknown}~\cite{chitrakar2012anomaly}\newline
\textbf{Description:} This dataset has been created through honypots, so there is no process for manual labelling and anonymization, but it has limited view of the network traffic because only attacks directed at the honeypots can be observed.\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} It has ten extra features such as IDS Detection, Malware Detection, and Ashula Detection than previous available datasets which are useful in NIDS analysis and evaluation. \newline
\textbf{Evaluation Measurements:} \newline











\subsection{Twente}
\textbf{Cited papers:}~\cite{sperotto2009labeled} \newline
\textbf{Description:} This dataset includes three services such as OpenSSH, Apache web server and Proftp using auth/ident on port 113 and captured data from a honeypot network by Netflow. There is some simultaneous network traffic such as auth/ident, ICMP, and IRC traffic, which are not completely benign or malicious. There is some simultaneous network traffic such as auth/ident, ICMP, and IRC traffic, which are not completely benign or malicious. Moreover, this dataset contains some unknown and uncorrelated alerts traffic.\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline






\subsection{UMASS}
\textbf{Cited papers:}~\cite{nehinbe2011critical}~\cite{prusty2011forensic} \newline
\textbf{Description:} The dataset includes trace files, which are network packets, and some traces on wireless applications. It has been generated using a single TCP-based download request attack scenario.\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline






\subsection{Intrusion detection evaluation dataset (ISCXIDS2012)}
\textbf{Cited papers:} ~\cite{shiravi2012toward}\newline
\textbf{Description:} The UNB ISCX IDS 2012 dataset consists of labeled network traces, including full packet payloads in pcap format, which along with the relevant profiles are publicly available for researchers.  \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} The UNB ISCX 2012 intrusion detection evaluation dataset consists of the following 7 days of network activity (normal and malicious). \newline
\textbf{Evaluation Measurements:} \newline









\subsection{Intrusion Detection Evaluation Dataset (CICIDS2017)}
\textbf{Cited papers:}~\cite{sharafaldin2018toward} \newline
\textbf{Description:} CICIDS2017 dataset contains benign and the most up-to-date common attacks, which resembles the true real-world data (PCAPs). It also includes the results of the network traffic analysis using CICFlowMeter with labeled flows based on the time stamp, source and destination IPs, source and destination ports, protocols and attack (CSV files). \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} The CICIDS2017 dataset consists of labeled network flows, including full packet payloads in pcap format, the corresponding profiles and the labeled flows (GeneratedLabelledFlows.zip) and CSV files for machine and deep learning purpose (MachineLearningCSV.zip) are publicly available for researchers.\newline
\textbf{Evaluation Measurements:} \newline






\subsection{NSL-KDD dataset}
\textbf{Cited papers:}~\cite{tavallaee2009detailed} \newline
\textbf{Description:} NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set.  \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline








\subsection{VPN-nonVPN dataset (ISCXVPN2016)}
\textbf{Cited papers:} ~\cite{draper2016characterization}\newline
\textbf{Description:} We captured a regular session and a session over VPN, therefore we have a total of 14 traffic categories: VOIP, VPN-VOIP, P2P, VPN-P2P, etc.\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline











\subsection{Botnet dataset}
\textbf{Cited papers:} ~\cite{beigi2014towards}\newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline







\subsection{Android validation dataset}
\textbf{Cited papers:}~\cite{gonzalez2014droidkin} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline








\subsection{Android Botnet dataset}
\textbf{Cited papers:}~\cite{kadir2015android} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline






\subsection{Tor-nonTor dataset (ISCXTor2016)}
\textbf{Cited papers:}~\cite{lashkari2017characterization} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline






\subsection{CIC DoS dataset}
\textbf{Cited papers:}~\cite{jazi2017detecting} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline





\subsection{Android Adware and General Malware Dataset}
\textbf{Cited papers:} ~\cite{lashkari2017towards}\newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline










\subsection{Android Malware Dataset (CICAndMal2017)}
\textbf{Cited papers:} ~\cite{shiravi2012toward}\newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{CSE-CIC-IDS2018 on AWS}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Text Filtering and Ranking for Security Bug Report Prediction}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline


\subsection{HTTP DATASET CSIC 2010}
\textbf{Cited papers:}~\cite{torrano2009self} \newline
\textbf{Description:}  The HTTP dataset CSIC 2010 contains the generated traffic targeted to an e- Commerce web application developed at our department. In this web application, users can buy items using a shopping cart and register by providing some personal information. As it is a web application in Spanish, the data set contains some Latin characters. \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} The dataset is generated automatically and contains 36,000 normal requests and more than 25,000 anomalous requests. The HTTP requests are labeled as normal or anomalous and the dataset includes attacks such as SQL injection, buffer overflow, information gathering, files disclosure, CRLF injection, XSS, server side include, parameter tampering and so on.\newline
\textbf{Evaluation Measurements:} \newline

\subsection{Analyzing Web Traffic ECML/PKDD 2007 Discovery Challenge}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{CAIDA DDoS Attack}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{AWID}
\textbf{Cited papers:} ~\cite{kolias2016intrusion}\newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Coburg Intrusion Detection Data Sets}
\textbf{Cited papers:}~\cite{ring2017flow} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Comprehensive, Multi-Source Cyber-Security Events}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{User-Computer Authentication Associations in Time}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Unified Host and Network Dataset}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Stratosphere CTU-13}
\textbf{Cited papers:} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Detecting Malicious URLs}
\textbf{Cited papers:}~\cite{ma2010exploiting}~\cite{ma2009identifying}~\cite{ma2009beyond} \newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} The data set consists of about 2.4 million URLs (examples) and 3.2 million features \newline
\textbf{Evaluation Measurements:} \newline

\subsection{Drebin Dataset}
\textbf{Cited papers:} ~\cite{arp2014drebin}~\cite{torrano2009self}\newline
\textbf{Description:} \newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\subsection{UNM Intrusion Detection Dataset}
\textbf{Cited papers:} \newline
\textbf{Description:} Each trace is the list of system calls issued by an lpr process from the beginning of its execution to the end. There are 182 different system calls in the dataset.\newline
\textbf{Research Goals:}  \newline
\textbf{Data Structure:} \newline
\textbf{Evaluation Measurements:} \newline

\include{table}